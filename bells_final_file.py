# -*- coding: utf-8 -*-
"""bells final file.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1G7kNMT1FJfPmOb--bors_Jcrl_qfzbJr
"""

from google.colab import drive
drive.mount('/content/drive')

#blepblink 
import cv2, numpy as np, glob, os,shutil, keras, matplotlib.pyplot as plt,tensorflow as tf,matplotlib.mlab as mplt, sys
from matplotlib import style
from keras.models import Sequential
from keras.models import load_model
from keras.layers import Convolution2D, MaxPooling2D, Dropout,ZeroPadding2D
from keras.layers.core import Dense, Dropout, Activation, Flatten
from keras.optimizers import Adam
from sklearn.model_selection import train_test_split as tt
import scipy.io.wavfile
from math import sqrt
import librosa
from sklearn.metrics import roc_curve, auc, roc_auc_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_recall_curve,f1_score,average_precision_score,confusion_matrix
from keras import backend as K
from keras.callbacks import ModelCheckpoint
from sklearn.preprocessing import StandardScaler as sd
from sklearn.model_selection import StratifiedKFold
import subprocess
from sklearn.decomposition import PCA
from IPython.display import Audio
from keras.models import Model
from keras import optimizers
from imutils import face_utils
import dlib,math

detector= dlib.get_frontal_face_detector()
predictor = dlib.shape_predictor('./drive/My Drive/shape_predictor_68_face_landmarks.dat')

drop=0.8
learning_rate=.0001
epoch=50
count=0

model = Sequential()
model.add(Convolution2D(32, (2,2), input_shape=(50,50,1), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))

model.add(Convolution2D(64, (2,2), activation='relu', padding='same'))
model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))


model.add(Convolution2D(32, (2,2), activation='relu', padding='same'))
model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))
model.add(Convolution2D(64, (2,2), activation='relu', padding='same'))
model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))
model.add(Convolution2D(32, (2,2), activation='relu', padding='same'))
model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))
model.add(Convolution2D(64, (2,2), activation='relu', padding='same'))
model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))


model.add(Convolution2D(32, (2,2), activation='relu', padding='same'))
model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))
model.add(Convolution2D(64, (2,2), activation='relu', padding='same'))
model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))


model.add(Convolution2D(32, (2,2), activation='relu', padding='same'))
model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))

model.add(Convolution2D(64, 2, activation='relu',padding='same'))
#model.add(ZeroPadding2D((1, 1)))
model.add(MaxPooling2D(pool_size=2,padding='same'))
#model.add(Dropout(0.3))


model.add(Flatten())
model.add(Dense(1024, activation='relu'))
#model.add(Dropout(0.30))
#   model.add(Dense(512, activation='relu'))
#   model.add(Dense(1024, activation='relu'))
model.add(Dropout(drop))
model.add(Dense(2))
model.add(Activation('softmax'))
model.load_weights("./drive/My Drive/neuro/colour.hdf5")
adam=optimizers.Adam(lr=learning_rate)
model.compile(optimizer=adam,loss='categorical_crossentropy', metrics=['accuracy'])

path_dict={0:"./drive/My Drive/neuro/neuro_disorder_data_final/bells/disease/",1:"./drive/My Drive/neuro/neuro_disorder_data_final/bells/normal/"}

file=open(path_dict[0]+"bells.txt",'w')

for nos in range(2):
    kcount=0
    vid=0
#     b=path_dict[nos].split("cerv/")
#     os.mkdir(b[0]+"cerv_blinkrig/"+b[1])
    for i in range(0,45):
        
        if(os.path.exists(path_dict[nos]+str(i)+".mp4")):

            
            video=path_dict[nos]+str(i)+".mp4"
            cap=cv2.VideoCapture(video)
#             sar=[]
            predlef=[]
#             lee=[]
#             ree=[]
#             arr=[]    
            predrig=[]
            c=0
#             s=0
#             fps = cap.get(cv2.CAP_PROP_FPS)
#             frame= cap.get(cv2.CAP_PROP_FRAME_COUNT)
#             sec=int(frame/fps)
#             fact = 40/sec
#             c0=0
#             e=sec
            while(cap.isOpened()):
                ret , frame=cap.read()
                if ret == True:
                    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)
                    shape1=np.array([])
                    rects1=detector(gray,0)
                    for rect in rects1:
                        shape = predictor(gray,rect)
                        shape1 = face_utils.shape_to_np(shape)
                    if(shape1.any()==0):
                        predlef.append('e')
                        predrig.append('e')
                        continue

                    #if blink
                    # first extract eye
                    fe1=shape1[39][0] - shape1[36][0]#eye lft ke liye
                    x1=shape1[42][0]
                    x1=x1-2
                    x2= shape1[45][0] 
                    x2=x2+2
                    y1=shape1[43][1]
                    y1=y1-18
                    y2=shape1[46][1]
                    y2=y2+12
                    if(x1<0):
                        x1=0
                    if(y1<0):
                        y1=0
                    if(x2>frame.shape[1]):
                        x2=frame.shape[1]
                    if(y2>frame.shape[0]):
                        y2=frame.shape[0]   

                    x_1=gray[y1:y2, x1:x2]

                    fe2=shape1[45][0] - shape1[42][0]# fe2 eye 2 ke liye
                    x1=shape1[36][0]
                    x1=x1-2
                    x2= shape1[39][0] 
                    x2=x2+2
                    y1=shape1[37][1]
                    y1=y1-18
                    y2=shape1[40][1]
                    y2=y2+12
                    if(x1<0):
                        x1=0
                    if(y1<0):
                        y1=0
                    if(x2>frame.shape[1]):
                        x2=frame.shape[1]
                    if(y2>frame.shape[0]):
                        y2=frame.shape[0] 
                    x_2=gray[y1:y2, x1:x2]
                    if(x_1 is None or x_2 is None):
                        print(c)
                        c+=1
                        continue
                    x_1 = cv2.flip(x_1,1)
                    img=cv2.resize(x_1, (50,50))
                    img=np.reshape(img, ([1,50,50,1]))
                    pred1=np.argmax(model.predict(img))
                    predlef.append(pred1)

                    img=cv2.resize(x_2, (50,50))
                    img=np.reshape(img, ([1,50,50,1]))
                    pred2=np.argmax(model.predict(img))
                    predrig.append(pred2)

                    c+=1
                else:
                    #print("video ")
                    break
            cap.release()
            cv2.destroyAllWindows()
            
            
            l=0
            r=0
            p = len(predlef)
            for il in range(p):
                if(predlef[il]==1):
                    l+=1
                if(predrig[il]==1):
                    r+=1
            if max(l,r)==0:
                feat=0
            else:
                feat=min(l,r)/max(l,r)
            if(nos==0):
                lab=1 
            else:
                lab=0#normal video cervical nahi h
            file.write(str(i)+","+str(feat)+","+str(lab)+"\n")
            print(str(i)+","+str(feat)+","+str(lab))

f.close()

