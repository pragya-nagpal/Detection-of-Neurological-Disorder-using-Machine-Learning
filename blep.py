# -*- coding: utf-8 -*-
"""blep.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qkciv9xg6Y8mMfbp_9GJzVIdblWyj3Jh
"""

!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

# 1. Authenticate and create the PyDrive client.
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

downloaded = drive.CreateFile({'id':'1dfh449M9yZq20HG_nsr3QMHuKPweBsj3'}) 
downloaded.GetContentFile('nblink.zip')
downloaded = drive.CreateFile({'id':'1xRB8fO_OqEhIwRXtiYeYFoPEHNQT7inK'}) 
downloaded.GetContentFile('modela.zip')
downloaded = drive.CreateFile({'id':'1quutMkAm_GVE1xhtq0zeVdYOwABa5FFf'}) 
downloaded.GetContentFile('c5010final.zip')
downloaded = drive.CreateFile({'id':'1qro6Hmk5bpXMc06zTnHgX9ZonZ-ol4v5'}) 
downloaded.GetContentFile('modelb.zip')

!unzip 'modela.zip'
!unzip 'c5010final.zip'
!unzip 'nblink.zip'
!unzip 'modelb.zip'

path='./c5010final/bleprep/n19/2.39.jpg'

img=cv2.imread(path)

img.shape

import cv2, glob
import numpy as np, math
import os
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestClassifier as rf
from keras.models import load_model

dictm = {0:'VGG19',1:'VGG16',2:'ResNet50',3:'InceptionV3',4:'InceptionResNetV2',5:'Xception',6:'MobileNetV2',7:'MobileNet',8:'DenseNet121',9:'DenseNet169',10:'DenseNet201',11:'NASNetLarge',12:'NASNetMobile'}
mo = 0# dict me model number
exec("from keras.applications import " +dictm.get(mo))
exec('ir = '+dictm.get(mo)+" (weights='imagenet',include_top=False,input_shape=(224, 224, 3))")
num=[[1,2,5,8,9,12,16,19],[1,3,4,5,8,9],[9,10,11,12,14,15,16,17,18,19,20],[2,3,4,6,7,8,9,10,11,12,14]]
dictx = {0:"actual normal", 1:"blepactual", 2:"bleprep", 3:"normal"}
dict2={0:"actual normal", 1:"blepactual", 2:"bleprep", 3:"normal"}

#19 normal
#17 blep

def getpt(img):
  img = cv2.resize(img, (224,224))
  #reshaped = np.reshape(img, (1,224,224,3))
  reshaped = np.reshape(img, (1,224,224,3))
  reshaped = reshaped/255.
  #reshaped=ir.predict(reshaped)
  #f0,f1,f2,f3 = reshaped.shape
  #reshaped = np.reshape(reshaped, (1,f1*f2,f3,1))
  
  pt=m.predict(reshaped)
  pt= pt[0]
  pt = pt*112 +112
  pt = np.array(pt, dtype="uint8")
  return pt
def dist(pt):
  # already pt thik hue we h (y,x) form me row col wale unnormalized
  x2,y2=pt[2],pt[3]
  x3,y3=pt[4],pt[5]
  x4,y4=pt[6],pt[7]
  x6,y6=pt[12], pt[13]
  d2=math.sqrt((x6-x2)**2 + (y6-y2)**2)
  d3=math.sqrt((x6-x3)**2 + (y6-y3)**2)
  d4=math.sqrt((x6-x4)**2 + (y6-y4)**2)
  return d2,d3,d4

img2 = cv2.resize(img,(224,224))
pts=getpt(img)
for i in range(8):
  cv2.circle(img2,(pts[2*i],pts[2*i+1]),3,(0, 255, 0),-1)

import matplotlib.pyplot as plt

plt.imshow(img2)

cls_f = {0:'from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as x',1:'from sklearn.svm import LinearSVC as x',2:'from sklearn.ensemble import ExtraTreesClassifier as x',3:'from sklearn.svm import SVC as x',4:'from sklearn.linear_model import SGDClassifier as x',5:'from sklearn.neighbors import KNeighborsClassifier as x',
       6:'from sklearn.gaussian_process import GaussianProcessClassifier as x',7:'from sklearn.naive_bayes import GaussianNB as x',8:'from sklearn.naive_bayes import BernoulliNB as x',9:'from sklearn.naive_bayes import MultinomialNB as x',
       10:'from sklearn.naive_bayes import ComplementNB as x',11:'from sklearn.tree import DecisionTreeClassifier as x',12:'from sklearn.ensemble import RandomForestClassifier as x',
       13:'from sklearn.ensemble import AdaBoostClassifier as x',14:'from sklearn.ensemble import GradientBoostingClassifier as x'}# bagging alag se h
cls_n = {0:'lda',1:'svm_linear',2:'extra tree classifier',3:'svm',4:'sgd',5:'knn',6:'gaussianprocessclf',7:'gaussian_nb',8:'bernoulli_nb',
         9:'multinomial_nb',10:'complement_nb',11:'decisiontree',12:'randomforest',13:'adaboost',14:'gradientclf'}

#file= open("./modelb/"+"8pointcnnAdam"+".txt","w")
file=open("./drive/My Drive/neuro/final/blep/blepfile.txt","w")
#file.write("model"+str(mo)+"\n")
# for mos in range(5,8):
#   mo = mos# dict me model number
#   exec("from keras.applications import " +dictm.get(mo))
#   exec('ir = '+dictm.get(mo)+" (weights='imagenet',include_top=False,input_shape=(224, 224, 3))")

#   print(("model : "+dictm.get(mo)+"\n"))
for numb in range(60,71,10):
  number = numb
  #if(os.path.exists("./modela/"+dictm.get(mo)+str(number)+".h5")):
  if(os.path.exists("./modelb/"+"8pointcnnAdam"+str(number)+".h5")):
    m = load_model("./modelb/"+"8pointcnnAdam"+str(number)+".h5")
    print("./modelb/"+"8pointcnnAdam"+str(number))
    #file.write(str(number)+"\n")
    print((str(number)+"\n"))
    arr11=[]
    for f in range(0,4):
      lf = len(num[f])
      arr21=[]
      for k in range(0,lf):
        fld=num[f][k]
        path = "./c5010final/"+dictx.get(f)+"/n"+str(fld)+"/"
        A=glob.glob(path+"*.jpg")
        arr=[]
        arr2=[]
        n=len(A)
        for i in range(1,n):
          if((A[i-1].split("/")[4].split(".")[0] == A[i].split("/")[4].split(".")[0]) and i!=(n-1)):
            arr.append(cv2.imread(A[i-1]))
          else:
            arr.append(cv2.imread(A[i-1]))
            if(i==n-1):
              arr.append(cv2.imread(A[i]))
            arr2.append(arr) 
            arr=[]
        arr2l= len(arr2)
        ck=0
        arr31=[]
        for i in range(0,arr2l):
          arr3l=len(arr2[i])
          arr41=[]
          for j in range(0,arr3l):
            frame=arr2[i][j]
            pt=getpt(frame)
            pt= np.array(pt,dtype="uint8")
            arr41.append(pt)
            ck+=1
          arr31.append(arr41)
        arr21.append(arr31)
      arr11.append(arr21)
  else:
    print("./modelb/"+"8pointcnnAdam"+str(number)+"not present")
  
  
  distarr=arr11
  ar42=[]
  for i in range(4):
    arl = len(distarr[i])
    ar32=[]
    for j in range(arl):
      arp= len(distarr[i][j])
      ar22=[]
      if(arp==0):
        continue
      for k in range(arp):
        arq= len(distarr[i][j][k])
        a12=[]
        if(arq==0):
          continue
        for f in range(arq):
          pt=distarr[i][j][k][f]
          d2,d3,d4=dist(pt)
          dj = d2+d3+d4
          a12.append(dj)
        mina12=min(a12)
        maxa12=max(a12)
        ks=abs(mina12/maxa12)
        ar22.append(ks)
      if(len(ar22)!=0):
        ar32.append(np.mean(ar22))
    ar42.append(ar32)
  if(len(ar42[0])==0):
      #file.write("actual normal ke nahi aai"+"\n")
      print("actual normal ke nahi aai"+"\n")
  if(len(ar42[1])==0):
    #file.write("actual blep ke nahi aai"+"\n")
    print("actual blep ke nahi aai"+"\n")
  
  
  t=ar42[0]+ar42[3]+ ar42[1]+ar42[2]
  label = [0]*(len(ar42[0])+len(ar42[3]))+ [1]*(len(ar42[1])+len(ar42[2]))
  t = np.reshape(t, (len(t),1))
  w = min((len(ar42[0])+len(ar42[3])),(len(ar42[1])+len(ar42[2])))
  
  for i in range(0,9):
    print(cls_n[i])
    for aj in range(3,w):
    
      exec(cls_f[i])
      clf = rf()
      clf.fit(t,label)
      scores = cross_val_score(clf, t,label,cv=aj)
      print("crossval :"+str(aj)+"acc : "+str(sum(scores)/aj)+"\n"+"\n")
  for i in range(11,15):
    print(cls_n[i])
    for aj in range(3,w):
    
      exec(cls_f[i])
      clf = rf()
      clf.fit(t,label)
      scores = cross_val_score(clf, t,label,cv=aj)
      print("crossval :"+str(aj)+"acc : "+str(sum(scores)/aj)+"\n"+"\n")

#     clf = rf()
#     clf.fit(t,label)
#     scores = cross_val_score(clf, t,label,cv=aj)
#     #file.write("crossval :"+str(aj)+"acc : "+str(sum(scores)/aj)+"\n"+"\n")
#     print("crossval :"+str(aj)+"acc : "+str(sum(scores)/aj)+"\n"+"\n")

  #print("ep", numb)
#file.close()

file= open("./modelb/"+"8pointcnnAdam"+".txt","w")
#file.write("model"+str(mo)+"\n")
# for mos in range(5,8):
#   mo = mos# dict me model number
#   exec("from keras.applications import " +dictm.get(mo))
#   exec('ir = '+dictm.get(mo)+" (weights='imagenet',include_top=False,input_shape=(224, 224, 3))")

#   print(("model : "+dictm.get(mo)+"\n"))
for numb in range(30,121,10):
  number = numb
  #if(os.path.exists("./modela/"+dictm.get(mo)+str(number)+".h5")):
  if(os.path.exists("./modelb/"+"8pointcnnAdam"+str(number)+".h5")):
    m = load_model("./modelb/"+"8pointcnnAdam"+str(number)+".h5")
    print("./modelb/"+"8pointcnnAdam"+str(number))
    #file.write(str(number)+"\n")
    print((str(number)+"\n"))
    arr11=[]
    for f in range(0,4):
      lf = len(num[f])
      arr21=[]
      for k in range(0,lf):
        fld=num[f][k]
        path = "./c5010final/"+dictx.get(f)+"/n"+str(fld)+"/"
        A=glob.glob(path+"*.jpg")
        arr=[]
        arr2=[]
        n=len(A)
        for i in range(1,n):
          if((A[i-1].split("/")[4].split(".")[0] == A[i].split("/")[4].split(".")[0]) and i!=(n-1)):
            arr.append(cv2.imread(A[i-1]))
          else:
            arr.append(cv2.imread(A[i-1]))
            if(i==n-1):
              arr.append(cv2.imread(A[i]))
            arr2.append(arr) 
            arr=[]
        arr2l= len(arr2)
        ck=0
        arr31=[]
        for i in range(0,arr2l):
          arr3l=len(arr2[i])
          arr41=[]
          for j in range(0,arr3l):
            frame=arr2[i][j]
            pt=getpt(frame)
            pt= np.array(pt,dtype="uint8")
            arr41.append(pt)
            ck+=1
          arr31.append(arr41)
        arr21.append(arr31)
      arr11.append(arr21)
  else:
    print("./modelb/"+"8pointcnnAdam"+str(number)+"not present")
  distarr=arr11
  ar42=[]
  for i in range(4):
    arl = len(distarr[i])
    ar32=[]
    for j in range(arl):
      arp= len(distarr[i][j])
      ar22=[]
      if(arp==0):
        continue
      for k in range(arp):
        arq= len(distarr[i][j][k])
        a12=[]
        if(arq==0):
          continue
        for f in range(arq):
          pt=distarr[i][j][k][f]
          d2,d3,d4=dist(pt)
          dj = d2+d3+d4
          a12.append(dj)
        mina12=min(a12)
        maxa12=max(a12)
        ks=abs(mina12/maxa12)
        ar22.append(ks)
      if(len(ar22)!=0):
        ar32.append(min(ar22))
    ar42.append(ar32)
  if(len(ar42[0])==0):
      #file.write("actual normal ke nahi aai"+"\n")
      print("actual normal ke nahi aai"+"\n")
  if(len(ar42[1])==0):
    #file.write("actual blep ke nahi aai"+"\n")
    print("actual blep ke nahi aai"+"\n")
  t=ar42[0]+ar42[3]+ ar42[1]+ar42[2]
  label = [0]*(len(ar42[0])+len(ar42[3]))+ [1]*(len(ar42[1])+len(ar42[2]))
  


#   t = np.reshape(t, (len(t),1))
#   w = min((len(ar42[0])+len(ar42[3])),(len(ar42[1])+len(ar42[2])))
  


# for i in range(0,9):
#     print(cls_n[i])
#     for aj in range(3,w):
    
#       exec(cls_f[i])
#       clf = rf()
#       clf.fit(t,label)
#       scores = cross_val_score(clf, t,label,cv=aj)
#       print("crossval :"+str(aj)+"acc : "+str(sum(scores)/aj)+"\n"+"\n")
#   for i in range(11,15):
#     print(cls_n[i])
#     for aj in range(3,w):
    
#       exec(cls_f[i])
#       clf = rf()
#       clf.fit(t,label)
#       scores = cross_val_score(clf, t,label,cv=aj)
#       print("crossval :"+str(aj)+"acc : "+str(sum(scores)/aj)+"\n"+"\n")

#     clf = rf()
#     clf.fit(t,label)
#     scores = cross_val_score(clf, t,label,cv=aj)
#     #file.write("crossval :"+str(aj)+"acc : "+str(sum(scores)/aj)+"\n"+"\n")
#     print("crossval :"+str(aj)+"acc : "+str(sum(scores)/aj)+"\n"+"\n")

  #print("ep", numb)
#file.close()

m=load_model("./modelb/"+"8pointcnnAdam"+str(30)+".h5")#input shape (224,224,3)